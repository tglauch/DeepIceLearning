#### personal configuration of mkronmueller

[Basics]
###folder of the python files
thisfolder = /scratch9/mkron/software/DeepIceLearning/
###choose tensorflow or theano
keras_backend = tensorflow       
### choose between slurm and condor
workload_manager = slurm
### path to the cuda installation
cuda_installation = /usr/local/cuda/lib64/
##path to monte carlo datasets
mc_path = /scratch9/mkron/data/training_data/third_dataset/small/
#
train_folder = /scratch9/mkron/data/NN_out/
#name of the model.py
model_name = new_multi.py
# folder to save ALL the outputs
save_path= /scratch9/mkron/data/NN_out/run16/


[Training_Parameters]
epochs = 700
### the total batch size is the single_gpu_batch_size*reques_gpus
single_gpu_batch_size = 50
# the steps_per_epoch is divided by this number
epoch_divider = 100
#### relative fractions of the training, validation, test dataset
training_fraction = 30  
validation_fraction = 2
test_fraction = 2
patience = 20
verbose = 1
delta = 0
max_queue_size = 2
learning_rate = 0.0004
##### loss function, no spaces
loss_function=categorical_crossentropy 
### weights, only needed if weighted loss function, length must fit number of classes
#weights = 1.45, 0.5, 1.05
optimizer =Adam


[Multi_Task_Learning]
ON/OFF = ON
#loss = {'output_b1': 'categorical_crossentropy', 'output_b2': 'categorical_crossentropy', 'output_b3': 'categorical_crossentropy', 'output_b4': 'mean_squared_error'}
#loss_weights = {'output_b1': 30., 'output_b2': 1., 'output_b3': 1., 'output_b4': 1.}
loss = {'output_b1': 'categorical_crossentropy', 'output_b2': 'categorical_crossentropy', 'output_b3': 'categorical_crossentropy'}
loss_weights = {'output_b1': 30., 'output_b2': 1., 'output_b3': 1.}
# CustomLoss to ON and output_b1 has an individual loss function, which weights each event due to energy and event type
CustomLoss = ON
weights = 1.0, 1.789, 81.732, 10.0


[GPU]
request_gpus = 4
request_memory = 7
requirements = TARGET.CUDACapability 
exclude_node = bigbird
